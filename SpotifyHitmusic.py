# -*- coding: utf-8 -*-
"""DataWarehouseFinalCode (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FuYe1hV978-Wk1_JJgv4zFSikPG_OYSE
"""

import pandas as pd
from pandas import read_excel
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import os

import glob
data = pd.concat(map(pd.read_csv, ['dataset-of-00s.csv', 'dataset-of-10s.csv','dataset-of-60s.csv','dataset-of-70s.csv','dataset-of-80s.csv','dataset-of-90s.csv']))

data

"""# Neuer Abschnitt"""

data.isnull().sum()

data = data.replace('?',np.NaN)

print('Number of rows = %d' % (data.shape[0]))
print('Number of attributes = %d' % (data.shape[1]))

print('Number of missing values:')
for col in data.columns:
    print('\t%s: %d' % (col,data[col].isna().sum()))



data.info()

data = data.drop(['uri'],axis=1)
data

data.hist(figsize = (20,15));



categorical = ['track','artist']
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
for label in categorical:
    data[label] = encoder.fit_transform(data[label])
data



import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(18, 18))
#sns.heatmap(df.corr(), annot=True)
sns.heatmap(data.corr(), xticklabels=1, yticklabels=True,  annot=True, cmap="YlGnBu")



y= data.pop('target')
y

track = data.pop('track')
artist = data.pop('artist')

df=data

data['duration_ms'].max()/1000

#df=(df-df.mean())/df.std()
df = (df-df.min())/(df.max()-df.min())
df



df.boxplot(figsize=(25,5))

df=(df-df.mean())/df.std()
df

df.boxplot(figsize=(25,5))

y

df['target'] = y
df

print('Number of rows before discarding outliers = %d' % (df.shape[0]))

Z2 = df.loc[((df > -3).sum(axis=1)==16) & ((df <= 3).sum(axis=1)==16),:]
print('Number of rows after discarding outlier values = %d' % (Z2.shape[0]))
df = Z2

y= df.pop('target')
y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=8)

print(X_train.shape)
print(X_test.shape)

from numpy import mean
from numpy import std
import sklearn.metrics as sm
from sklearn import metrics
from sklearn import tree

values =[]
for i in range(1, 2):
  #choose from different tunable hyper parameters
  clf = tree.DecisionTreeClassifier(max_depth=i,criterion='entropy',random_state=0)

  # Creating the model on Training Data
  DTree=clf.fit(X_train,y_train)
  prediction=DTree.predict(X_test)
  #Measuring accuracy on Testing Data
 # print(metrics.classification_report(y_test, prediction))
  #print(metrics.confusion_matrix(y_test, prediction))

#  print("Train Accuracy:",DTree.score(X_train, y_train))
 # print("Test Accuracy:",DTree.score(X_test, y_test))
  values.insert(i-1,DTree.score(X_test, y_test))
print(values)

from numpy import mean
from numpy import std
import sklearn.metrics as sm
from sklearn import metrics
from sklearn import tree

#choose from different tunable hyper parameters
clf = tree.DecisionTreeClassifier(max_depth=3,criterion='entropy',random_state=0)

# Creating the model on Training Data
DTree=clf.fit(X_train,y_train)
prediction=DTree.predict(X_test)
#Measuring accuracy on Testing Data
print(metrics.classification_report(y_test, prediction))
print(metrics.confusion_matrix(y_test, prediction))

print("Train Accuracy:",DTree.score(X_train, y_train))
print("Test Accuracy:",DTree.score(X_test, y_test))
values.insert(i-1,DTree.score(X_test, y_test))

max(values)

import pydotplus 
from sklearn import tree
from IPython.display import Image

dot_data = tree.export_graphviz(DTree, feature_names=df.columns, class_names=['0','1'], filled=True, 
                                out_file=None) 
graph = pydotplus.graph_from_dot_data(dot_data) 
Image(graph.create_png())

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
feature_importances = pd.Series(DTree.feature_importances_, index=df.columns)
feature_importances.nlargest(30).plot(kind='barh')

#Import Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics

#Create a Gaussian Classifier
gnb = GaussianNB()

#Train the model using the training sets
gnb.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = gnb.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))



from sklearn.neighbors import KNeighborsClassifier
# Create KNN classifier
knn = KNeighborsClassifier(n_neighbors =5)
# Fit the classifier to the data
knn.fit(X_train,y_train)
#check accuracy of our model on the test data
print(knn.score(X_test, y_test))
knn.score(X_train, y_train)

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='rbf') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(hidden_layer_sizes=(10,10,10), activation='relu', solver='adam', max_iter=500)
mlp.fit(X_train,y_train)

predict_train = mlp.predict(X_train)
predict_test = mlp.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_train,predict_train))
print(classification_report(y_train,predict_train))